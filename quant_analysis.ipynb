{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "\n",
    "class PaddleModel:\n",
    "\n",
    "    def __init__(self, device: int = 0) -> None:\n",
    "        self.model = PaddleOCR(\n",
    "            use_angle_cls=True,\n",
    "            lang=\"en\",\n",
    "            show_log=True,\n",
    "            det_db_score_mode=\"slow\",\n",
    "            ocr_version=\"PP-OCRv4\",\n",
    "            rec_algorithm=\"SVTR_LCNet\",\n",
    "            drop_score=0.0,\n",
    "            use_gpu=True,\n",
    "            gpu_id=device,\n",
    "            gpu_mem=1000,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=2,3,4,5,6,7\n",
    "\n",
    "import concurrent.futures \n",
    "import cv2\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import concurrent\n",
    "import logging\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from typing import List\n",
    "from utilities.models import Models\n",
    "\n",
    "from viz import visualize_timestamps\n",
    "from utilities.constants import *\n",
    "\n",
    "MAX_GPUS = 6\n",
    "\n",
    "def process_dir(dir_path: str, data_out_path: str, viz_out_path=None):\n",
    "    \"\"\"\n",
    "    Extract all timestamps in a directory,\n",
    "    return timestamps as dict.\n",
    "    \"\"\"\n",
    "\n",
    "    assert os.path.isdir(\n",
    "        dir_path), f\"Error: bad path to video directory: {dir_path}\"\n",
    "    os.makedirs(data_out_path, exist_ok=True)\n",
    "    if viz_out_path is not None:\n",
    "        assert type(\n",
    "            viz_out_path) is str, \"Error: path links must be of type str.\"\n",
    "        os.makedirs(viz_out_path, exist_ok=True)\n",
    "\n",
    "    valid_formats = ['avi', 'mp4']\n",
    "    vids = os.listdir(dir_path)\n",
    "    for vid in vids: \n",
    "        extension = vid.split(\".\")[1]\n",
    "        if extension not in valid_formats:\n",
    "            vids.remove(vid)\n",
    "\n",
    "    timestamps = {}\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=MAX_GPUS) as executor:\n",
    "        with tqdm(total=len(vids), desc=\"Processing Videos\") as pbar:\n",
    "            while len(vids) > 0:\n",
    "                processes = []\n",
    "                video_paths = []\n",
    "                for device in range(MAX_GPUS):\n",
    "                    if len(vids) == 0:\n",
    "                        break\n",
    "                    video_path = os.path.join(dir_path, vids[0])\n",
    "                    data_path = os.path.join(data_out_path, vids[0].replace(\n",
    "                        \".mp4\", \".json\").replace(\".avi\", \".json\"))\n",
    "                    process = executor.submit(extract_timestamps_from_video, video_path, data_path, device=device)\n",
    "                    processes.append(process)\n",
    "                    video_paths.append(video_path)  # Store the video_path corresponding to each process\n",
    "                    vids.remove(vids[0])\n",
    "                for process, video_path in zip(concurrent.futures.as_completed(processes), video_paths):\n",
    "                    timestamps[video_path] = process.result()\n",
    "                    pbar.update(1)\n",
    "                    \n",
    "    return timestamps\n",
    "\n",
    "\n",
    "def extract_timestamps_from_video(video_path: str, save_path: str, device: int = 0):\n",
    "    \"\"\"\n",
    "    Given a path to a basketball broadcast video,\n",
    "    returns a timestamps dict.\n",
    "    \"\"\"\n",
    "\n",
    "    assert os.path.exists(video_path)\n",
    "\n",
    "    # print(f\"Extracting timestamps for video at {video_path} \\n\")\n",
    "    tr_x1, tr_y1, tr_x2, tr_y2 = None, None, None, None\n",
    "\n",
    "    # TODO: All roi's extracted on device = 0\n",
    "    time_remaining_roi = extract_roi_from_video(video_path)\n",
    "\n",
    "    if time_remaining_roi is not None:\n",
    "        tr_x1, tr_y1, tr_x2, tr_y2 = time_remaining_roi\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    timestamps = {}\n",
    "    quarter = video_path[-5]  # period_x.mp4\n",
    "    step = 5\n",
    "\n",
    "    model = PaddleModel(device=device)\n",
    "\n",
    "    for frame_index in range(frames_cnt):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        time_remaining_img = None\n",
    "        time_remaining = None\n",
    "        if frame_index % step == 0:\n",
    "            if time_remaining_roi is not None:\n",
    "                assert tr_x1 and tr_y1 and tr_x2 and tr_y2\n",
    "                time_remaining_img = frame[\n",
    "                    tr_y1 - PAD : tr_y2 + 2 * PAD, tr_x1 - PAD : tr_x2 + 2 * PAD\n",
    "                ]\n",
    "            if time_remaining_img is not None:\n",
    "                time_remaining = extract_time_remaining_from_image(\n",
    "                    Image.fromarray(time_remaining_img),\n",
    "                    model=model,\n",
    "                )\n",
    "                time_remaining = convert_time_to_float(time_remaining)\n",
    "        timestamps[str(frame_index)] = {\n",
    "            \"quarter\": quarter,\n",
    "            \"time_remaining\": time_remaining,\n",
    "        }\n",
    "        if frame_index == BREAK:\n",
    "            break\n",
    "\n",
    "    post_process_timestamps(timestamps)\n",
    "    return timestamps\n",
    "\n",
    "\n",
    "def extract_roi_from_video(video_path: str):\n",
    "    \"\"\"\n",
    "    Find time-remaining roi from video. Assumes static, naive approach.\n",
    "    Returns a tensor with format: [x1, y1, x2, y2] or None if no\n",
    "    ROI is found.\n",
    "    \"\"\"\n",
    "\n",
    "    assert os.path.isfile(video_path), f\"Error: bad path to video {video_path}.\"\n",
    "    # assert video_path[-4:] == '.mp4'\n",
    "\n",
    "    # print(f\"Finding time-remaining ROI for video at {video_path}\")\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    time_remaining_roi = None\n",
    "\n",
    "    # TODO: skip through vid at one second intervals\n",
    "    highest_conf = 0.0\n",
    "    best_roi = None\n",
    "    step = 30\n",
    "\n",
    "    for i in range(frames_cnt):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if i % step == 0:\n",
    "            results = Models.yolo(frame, verbose=False)\n",
    "            classes, conf, boxes = (\n",
    "                results[0].boxes.cls,\n",
    "                results[0].boxes.conf,\n",
    "                results[0].boxes.xyxy,\n",
    "            )\n",
    "            classes_conf = torch.stack((classes, conf), dim=1)\n",
    "            predictions = torch.cat((classes_conf, boxes), dim=1)\n",
    "            conf_mask = predictions[:, 1] > CONF_THRESH\n",
    "            pred_thresh = predictions[conf_mask]\n",
    "            for row in pred_thresh:\n",
    "                if row[0] == QUARTER_KEY:\n",
    "                    pass\n",
    "                elif row[0] == TIME_REMAINING_KEY:\n",
    "                    time_remaining_roi = row[2:].to(torch.int)\n",
    "            for row in predictions:\n",
    "                if row[0] == QUARTER_KEY:\n",
    "                    pass\n",
    "                elif row[0] == TIME_REMAINING_KEY:\n",
    "                    if row[1] > highest_conf:\n",
    "                        highest_conf = row[1]\n",
    "                        best_roi = row[2:].to(torch.int)\n",
    "            if time_remaining_roi is not None:\n",
    "                break\n",
    "    return best_roi\n",
    "\n",
    "\n",
    "def find_time_remaining_from_results(results: List[str]):\n",
    "    \"\"\"\n",
    "    Matches any string showing a valid time remaining of 20 minutes or less\n",
    "    assumes brodcasts use MM:SS for times > 1 minute, and SS.S for times < 1 minute\n",
    "    \"\"\"\n",
    "    if results is None:\n",
    "        return None\n",
    "    time_remaining_regex = r\"(20:00)|(0[0-9]?:[0-9][0-9](\\.[0-9])?)|([1-9]:[0-5][0-9])|(1[0-9]:[0-5][0-9](\\.[0-9])?)|([0-9]\\.[0-9])|([1-5][0-9]\\.[0-9])\"\n",
    "    for result in results:\n",
    "        result = result.replace(\" \", \"\")\n",
    "        match = re.match(time_remaining_regex, result)\n",
    "        if match is not None and match[0] == result:\n",
    "            return result\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_time_remaining_from_image(image: Image.Image, model: PaddleModel):\n",
    "    \"\"\"\n",
    "    Given a PIL Image object,\n",
    "    returns either a valid formatted time-remaining str (e.g., '11:30')\n",
    "    or None.\n",
    "    \"\"\"\n",
    "    rgb_img = image.convert(\"RGB\")\n",
    "    results = extract_text_with_paddle(rgb_img, model=model)\n",
    "    time_remaining = find_time_remaining_from_results(results)\n",
    "    return time_remaining\n",
    "\n",
    "\n",
    "def extract_text_with_paddle(image: Image.Image, model: PaddleModel) -> List[str]:\n",
    "    \"\"\"\n",
    "    Returns a [str] containing all words found in a\n",
    "    provided PIL image.\n",
    "    \"\"\"\n",
    "\n",
    "    if image is None:\n",
    "        return []\n",
    "    ideal_height = 100\n",
    "    scale_factor = ideal_height / image.height\n",
    "    new_size = (int(image.width * scale_factor), int(image.height * scale_factor))\n",
    "    image = image.resize(new_size)\n",
    "    img_arr = np.array(image)\n",
    "\n",
    "    # cv2.imwrite(\"preprocessed_img.png\", img_arr)\n",
    "    results = []\n",
    "\n",
    "    # pred w/ paddleocr\n",
    "    raw_result = model.model(img_arr)\n",
    "    text_arr = raw_result[1]\n",
    "    for pred in text_arr:\n",
    "        word = pred[0]\n",
    "        results.append(word)\n",
    "    return results\n",
    "\n",
    "\n",
    "def convert_time_to_float(time_remaining):\n",
    "    \"\"\"\n",
    "    Coverts valid time-remaining str\n",
    "    to float value representation.\n",
    "    Return None if time-remaining is invalid.\n",
    "\n",
    "    Ex: '1:30' -> 90.\n",
    "    \"\"\"\n",
    "\n",
    "    if time_remaining is None:\n",
    "        return None\n",
    "    minutes, seconds = 0.0, 0.0\n",
    "    if \":\" in time_remaining:\n",
    "        time_arr = time_remaining.split(\":\")\n",
    "        minutes = float(time_arr[0])\n",
    "        seconds = float(time_arr[1])\n",
    "    elif \".\" in time_remaining:\n",
    "        seconds = float(time_remaining)\n",
    "    else:\n",
    "        return None\n",
    "    return (60.0 * minutes) + seconds\n",
    "\n",
    "\n",
    "def post_process_timestamps(timestamps):\n",
    "    \"\"\"\n",
    "    Interpolate timestamps in-place.\n",
    "    \"\"\"\n",
    "\n",
    "    last_quarter, last_time = None, None\n",
    "\n",
    "    for key in timestamps:\n",
    "        quarter, time_remaining = (\n",
    "            timestamps[key][\"quarter\"],\n",
    "            timestamps[key][\"time_remaining\"],\n",
    "        )\n",
    "        if quarter:\n",
    "            last_quarter = quarter\n",
    "        else:\n",
    "            timestamps[key][\"quarter\"] = last_quarter\n",
    "        if time_remaining:\n",
    "            last_time = time_remaining\n",
    "        else:\n",
    "            timestamps[key][\"time_remaining\"] = last_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_str = \"C:/Users/Levi/Desktop/quantitative-benchmark/test-set\\\\\"\n",
    "with_str = \"/playpen-storage/levlevi/nba-positions-videos-dataset/testing/quantitative-benchmark/test-set/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "annotations_fp = \"/playpen-storage/levlevi/nba-positions-videos-dataset/testing/quantitative-benchmark/annotations/annotations.json\"\n",
    "with open(annotations_fp, 'r') as f:\n",
    "    annotations = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"/playpen-storage/levlevi/nba-positions-videos-dataset/testing/quantitative-benchmark/test-set\"\n",
    "dummy = \"/playpen-storage/levlevi/nba-positions-videos-dataset/testing/quantitative-benchmark/dummy\"\n",
    "timestamps = process_dir(dir_path, dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = {}\n",
    "for k in annotations:\n",
    "    ground_truth = annotations[k]\n",
    "    break\n",
    "\n",
    "timestamp_vals = [timestamps[k]['time_remaining'] for k in timestamps]\n",
    "ground_truth_vals = [ground_truth[k]['time_on_clock'] for k in ground_truth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))  # Set the figure size\n",
    "\n",
    "# Plotting the data\n",
    "plt.plot(\n",
    "    timestamp_vals, label=\"Timestamp Values\", color=\"blue\"\n",
    ")\n",
    "plt.plot(\n",
    "    ground_truth_vals,\n",
    "    label=\"Ground Truth Values\",\n",
    "    color=\"red\",\n",
    ")\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title(\"Timestamp vs Ground Truth Values\")\n",
    "plt.xlabel(\"Frame Idx\")\n",
    "plt.ylabel(\"Time Remaining\")\n",
    "\n",
    "# Adding a legend\n",
    "plt.legend()\n",
    "\n",
    "# Adding a grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Tight layout to adjust for the rotated x-axis labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

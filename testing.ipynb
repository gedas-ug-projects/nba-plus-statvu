{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib as plt\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = '707_01-17-2016_2976_Memphis Grizzlies_3173_New York Knicks_period1'\n",
    "game_date = g.split('_')[1].replace('-', '.')\n",
    "vis = g.split('_')[3]\n",
    "home = g.split('_')[5]\n",
    "game_date, vis, home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_acr = \"\"\"\n",
    "ATL\\tAtlanta Hawks\n",
    "BOS\tBoston Celtics\n",
    "BKN\tBrooklyn Nets\n",
    "CHA\tCharlotte Hornets\n",
    "CHI\tChicago Bulls\n",
    "CLE\tCleveland Cavaliers\n",
    "DAL\tDallas Mavericks\n",
    "DEN\tDenver Nuggets\n",
    "DET\tDetroit Pistons\n",
    "GSW\tGolden State Warriors\n",
    "HOU\tHouston Rockets\n",
    "IND\tIndiana Pacers\n",
    "LAC\tLos Angeles Clippers\n",
    "LAL\tLos Angeles Lakers\n",
    "MEM\tMemphis Grizzlies\n",
    "MIA\tMiami Heat\n",
    "MIL\tMilwaukee Bucks\n",
    "MIN\tMinnesota Timberwolves\n",
    "NOP\tNew Orleans Pelicans\n",
    "NYK\tNew York Knicks\n",
    "OKC\tOklahoma City Thunder\n",
    "ORL\tOrlando Magic\n",
    "PHI\tPhiladelphia 76ers\n",
    "PHX\tPhoenix Suns\n",
    "POR\tPortland Trail Blazers\n",
    "SAC\tSacramento Kings\n",
    "SAS\tSan Antonio Spurs\n",
    "TOR\tToronto Raptors\n",
    "UTA\tUtah Jazz\n",
    "WAS\tWashington Wizards\n",
    "\"\"\"\n",
    "\n",
    "acr_dict = {}\n",
    "team_acr = team_acr.split('\\n')[1: -1]\n",
    "for row in team_acr:\n",
    "    # print(row.split('\\t'))\n",
    "    full = row.split('\\t')[1]\n",
    "    acr = row.split('\\t')[0]\n",
    "    acr_dict[full] = acr\n",
    "acr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "fp = r\"G:\\Other computers\\mac_new\\NBA_HUDL_data\\15-16\\720\"\n",
    "\n",
    "def get_vids_path_map(fp):\n",
    "    \"\"\"\n",
    "    Given a directory path to videos from the 15-16 NBA season, \n",
    "    returns a dict mapping formatted game titles to abs video paths.\n",
    "    \"\"\"\n",
    "\n",
    "    game_vids = os.listdir(fp)\n",
    "    game_vids_map = {}\n",
    "    for game in game_vids:\n",
    "        gp = os.path.join(fp, game)\n",
    "        game_date = game.split('_')[1].replace('-', '.')\n",
    "        home = game.split('_')[3]\n",
    "        vis = game.split('_')[5]\n",
    "        game_date, vis, home\n",
    "        formatted_title = f'{game_date}.{acr_dict[vis]}.at.{acr_dict[home]}.7z'\n",
    "        game_vids_map[formatted_title] = gp\n",
    "    return game_vids_map\n",
    "\n",
    "vids_paths_map = get_vids_path_map(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "games = set(os.listdir(\"2016.NBA.Raw.SportVU.Game.Logs\"))\n",
    "# print(games)\n",
    "# print(map)\n",
    "\n",
    "# game_titles: video_paths\n",
    "\n",
    "def fix_game_date_offsets(statvu_logs_dir, videos_dir, videos_paths_map: dict[str: str]):\n",
    "\n",
    "    games = set(os.listdir(statvu_logs_dir))\n",
    "    for k in videos_paths_map.keys():\n",
    "\n",
    "        date_str = k[0:10]\n",
    "        date = k[0:10]\n",
    "        date = datetime.strptime(date, '%m.%d.%Y')\n",
    "\n",
    "        # calculate +- one day\n",
    "        date_plus = date + timedelta(days=1)\n",
    "        date_minus = date - timedelta(days=1)\n",
    "        date_plus = date_plus.strftime('%m.%d.%Y')\n",
    "        date_minus = date_minus.strftime('%m.%d.%Y')\n",
    "\n",
    "        if k in games:\n",
    "            pass\n",
    "        elif k.replace(date_str, date_minus) in games:\n",
    "            path = videos_paths_map.pop(k)\n",
    "            videos_paths_map[k.replace(date_str, date_minus)] = path\n",
    "        elif k.replace(date_str, date_plus) in games:\n",
    "            path = videos_paths_map.pop(k)\n",
    "            videos_paths_map[k.replace(date_str, date_plus)] = path\n",
    "\n",
    "\n",
    "fix_game_date_offsets('2016.NBA.Raw.SportVU.Game.Logs', fp, vids_paths_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [game_log_path, video_game_path]\n",
    "# \n",
    "\n",
    "games_videos_paths = []\n",
    "for k in vids_paths_map:\n",
    "    statvu_data_path = os.path.join(\"2016.NBA.Raw.SportVU.Game.Logs\", k)\n",
    "    video_path = vids_paths_map[k]\n",
    "\n",
    "    assert os.path.isfile(video_path)\n",
    "    if os.path.isfile(statvu_data_path):\n",
    "        games_videos_paths.append([statvu_data_path, video_path])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import py7zr\n",
    "\n",
    "dir_path = '2016.NBA.Raw.SportVU.Game.Logs'\n",
    "games = os.listdir(dir_path)\n",
    "\n",
    "for game in games:\n",
    "    gp = os.path.join(dir_path, game)\n",
    "\n",
    "    # Ensure the file is a .7z file before trying to unzip\n",
    "    if gp.endswith('.7z'):\n",
    "        with py7zr.SevenZipFile(gp, mode='r') as archive:\n",
    "            archive.extractall(path=dir_path)\n",
    "\n",
    "        # Rename extracted JSON files\n",
    "        extracted_files = os.listdir(dir_path)\n",
    "        for f in extracted_files:\n",
    "            if f.endswith('.json') and '.201' not in f:\n",
    "                os.rename(\n",
    "                    os.path.join(dir_path, f), \n",
    "                    os.path.join(\n",
    "                        dir_path, game.replace('.7z', '.json')\n",
    "                    )\n",
    "                )\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. extract timestamps from game\n",
    "# 2. match frames to moments\n",
    "# 3. save new data and upload both versions (w/ frames, w/o frames)\n",
    "# 4. produce visualized results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    " # 1. fix text extraction errors\n",
    " # 2. Improve visualization quality + speed of rendering\n",
    " # 3. Produce many visualizations and moments files + save and upload\n",
    "\n",
    "# !pip install -q ultralytics\n",
    "# !pip install -q paddlepaddle\n",
    "# !pip install -q paddleocr\n",
    "# !tail -f process.log\n",
    "\n",
    "from temporal_grounding import *\n",
    "\n",
    "vp = r\"demo\\17769_12-27-2015_3175_Phoenix Suns_3224_Philadelphia 76ers_period2.mp4\"\n",
    "dp = r\"demo\\01.01.2016.NYK.at.CHI.json\"\n",
    "extract_timestamps_from_video(vp, 'demo/12.26.2015.PHI.at.PHX.timestamps.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "fp = r'demo/01.01.2016.NYK.at.CHI.json'\n",
    "with open(fp, 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_unique_moments_from_statvu(statvu_log_path):\n",
    "    \"\"\"\n",
    "    Extracts unique moments from a StatVu log file.\n",
    "\n",
    "    Args:\n",
    "    statvu_log_path (str): The file path of the StatVu log.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary mapping unique quarter-time remaining combinations to their respective moment details.\n",
    "    \"\"\"\n",
    "    with open(statvu_log_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    unique_quarter_time_combinations = set()\n",
    "    processed_moments = {}\n",
    "\n",
    "    for event in data['events']:\n",
    "        for moment in event['moments']:\n",
    "            quarter, moment_id, time_remaining_quarter, time_remaining_shot_clock, _, positions = moment\n",
    "            moment_identifier = f\"{quarter}_{time_remaining_quarter}\"\n",
    "            if moment_identifier not in unique_quarter_time_combinations:\n",
    "                player_positions = [\n",
    "                    {'team_id': player_data[0], 'player_id': player_data[1], \n",
    "                     'x_position': player_data[2], 'y_position': player_data[3], 'z_position': player_data[4]}\n",
    "                    for player_data in positions\n",
    "                ]\n",
    "                processed_moments[moment_identifier] = {\n",
    "                    'quarter': quarter,\n",
    "                    'moment_id': moment_id,\n",
    "                    'time_remaining_in_quarter': time_remaining_quarter,\n",
    "                    'time_remaining_on_shot_clock': time_remaining_shot_clock,\n",
    "                    'player_positions': player_positions\n",
    "                }\n",
    "                unique_quarter_time_combinations.add(moment_identifier)\n",
    "\n",
    "    return processed_moments\n",
    "\n",
    "fp = r\"demo\\12.26.2015.PHI.at.PHX.json\"\n",
    "m = get_unique_moments_from_statvu(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "fp = r'demo/timestamps.json'\n",
    "with open(fp, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# statvu format\n",
    "    # 1/25 fps\n",
    "    # -1/25s per frame\n",
    "\n",
    "# 1. interpolate between time_remaining values\n",
    "\n",
    "tr_vals = []\n",
    "for k in data:\n",
    "    tr = data[k]['time_remaining']\n",
    "    if tr == None:\n",
    "        tr_vals.append(-1)\n",
    "    else:\n",
    "        tr_vals.append(tr)\n",
    "\n",
    "last_seen = -1\n",
    "last_seen_cnt = 0\n",
    "inter_vals = []\n",
    "for v in tr_vals:\n",
    "    if v > 0:\n",
    "        if last_seen_cnt == 0 or last_seen_cnt > 30:\n",
    "            last_seen = v\n",
    "            last_seen_cnt = 0\n",
    "            inter_vals.append(v)\n",
    "            last_seen_cnt += 1\n",
    "        else:\n",
    "            # 26 / 30 = x / 25\n",
    "            x = math.floor(((last_seen_cnt) / 30) * 25) # multiplier\n",
    "            v_temp = v - (x / 25)\n",
    "            v_temp = round(v_temp, 2)\n",
    "            last_seen_cnt += 1\n",
    "            inter_vals.append(v_temp)\n",
    "    else:\n",
    "        inter_vals.append(None)\n",
    "\n",
    "for k, v in zip(data, inter_vals):\n",
    "    data[k]['time_remaining'] = v\n",
    "\n",
    "with open(r\"demo\\timestamps_mod.json\", \"w\") as outfile: \n",
    "    json.dump(data, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "\n",
    "def interpolate_timestamps(file_path, output_path):\n",
    "    \"\"\"\n",
    "    Interpolates time remaining values in a JSON file containing timestamp data.\n",
    "\n",
    "    Args:\n",
    "    file_path (str): The file path of the input JSON file with timestamp data.\n",
    "    output_path (str): The file path for the output JSON file with interpolated timestamps.\n",
    "\n",
    "    The function reads the timestamp data, interpolates the 'time_remaining' values, and writes\n",
    "    the updated data to a new JSON file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load data from the file\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Initialize list to store original time_remaining values\n",
    "    original_time_values = []\n",
    "\n",
    "    # Extract time_remaining values and handle None values\n",
    "    for key in data:\n",
    "        time_remaining = data[key].get('time_remaining', -1)\n",
    "        original_time_values.append(time_remaining if time_remaining is not None else -1)\n",
    "\n",
    "    # Initialize variables for interpolation\n",
    "    last_seen_valid_time = -1\n",
    "    consecutive_frame_count = 0\n",
    "    interpolated_values = []\n",
    "\n",
    "    # Perform interpolation of time_remaining values\n",
    "    for value in original_time_values:\n",
    "        if value > 0:\n",
    "            if consecutive_frame_count == 0 or consecutive_frame_count > 30:\n",
    "                last_seen_valid_time = value\n",
    "                consecutive_frame_count = 0\n",
    "            else:\n",
    "                multiplier = math.floor((consecutive_frame_count / 30) * 25)\n",
    "                interpolated_value = round(value - (multiplier / 25), 2)\n",
    "                interpolated_values.append(interpolated_value)\n",
    "            consecutive_frame_count += 1\n",
    "        else:\n",
    "            interpolated_values.append(None)\n",
    "\n",
    "    # Update the data dictionary with interpolated values\n",
    "    for key, interpolated_value in zip(data, interpolated_values):\n",
    "        data[key]['time_remaining'] = interpolated_value\n",
    "\n",
    "    # Write the updated data to a new JSON file\n",
    "    try:\n",
    "        with open(output_path, \"w\") as outfile:\n",
    "            json.dump(data, outfile, indent=4)\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing file {output_path}: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "interpolate_timestamps(r'demo\\12.26.2015.PHI.at.PHX.timestamps.json', r'demo\\12.26.2015.PHI.at.PHX.timestamps.mod.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "# def interpolate_timestamps(src_fp, dst_fp):\n",
    "    \n",
    "src_fp = r\"demo\\12.26.2015.PHI.at.PHX.timestamps.json\"\n",
    "with open(src_fp, 'r') as f:\n",
    "    timestamps = json.load(f)\n",
    "\n",
    "tr = []\n",
    "tr_mod = []\n",
    "\n",
    "for k in timestamps:\n",
    "    tr.append(timestamps[k]['time_remaining'])\n",
    "\n",
    "is_dec = False\n",
    "dec_index = 0\n",
    "\n",
    "seen = set()\n",
    "for i in range(0, len(tr) - 30):\n",
    "\n",
    "    curr = tr[i]\n",
    "    next = tr[i + 30] # look ahead 30 frames\n",
    "    # print(curr)\n",
    "    # i / 30 = x / 25\n",
    "    # floor((i / 30)) * 25 = x\n",
    "    # dec = x / 25\n",
    "\n",
    "\n",
    "    temp = 0\n",
    "\n",
    "    if curr != None:\n",
    "        if curr not in seen and next != None and next < curr:\n",
    "            is_dec = True\n",
    "            dec_index = 1\n",
    "            seen.add(curr)\n",
    "            tr_mod.append(curr)\n",
    "        elif is_dec:\n",
    "            tr_mod.append(round(curr - ((1/30) * dec_index), 2))\n",
    "            dec_index += 1\n",
    "        else:\n",
    "            dec_index = 1\n",
    "            tr_mod.append(curr)\n",
    "    else:\n",
    "        is_dec = False\n",
    "        dec_index = 1\n",
    "        tr_mod.append(curr)\n",
    "\n",
    "for k, v in zip(timestamps, tr_mod):\n",
    "    timestamps[k]['time_remaining'] = v\n",
    "\n",
    "with open(r'demo\\12.26.2015.PHI.at.PHX.timestamps.mod.json', 'w') as f:\n",
    "    json.dump(timestamps, f, indent=4)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35657/35657 [00:40<00:00, 886.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32078 / 34862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "# 1. extract timestamps from video\n",
    "# 2. interpolate and save timestamps\n",
    "# 3. map video frames to moments\n",
    "\n",
    "def map_frames_to_moments(data, moments_data):\n",
    "    \"\"\"\n",
    "    Maps frames in 'data' to their corresponding moments in 'moments_data' based on time proximity.\n",
    "\n",
    "    Args:\n",
    "    data (dict): A dictionary containing data with keys indicating frame identifiers and values \n",
    "                 having 'quarter' and 'time_remaining' information.\n",
    "    moments_data (dict): A dictionary where keys are string representations of 'quarter_time' and values\n",
    "                         are the moments to map.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary mapping frame identifiers to corresponding moments in 'moments_data'.\n",
    "    \"\"\"\n",
    "\n",
    "    def is_close(time1, time2, tolerance=0.2 ):\n",
    "        \"\"\"Check if two time values are within a given tolerance.\"\"\"\n",
    "        return abs(time1 - time2) <= tolerance\n",
    "\n",
    "    frames_matched = 0\n",
    "    total_frames = 0\n",
    "    frames_moments_map = {}\n",
    "\n",
    "    moments_dict = {}\n",
    "    for moment_key in moments_data:\n",
    "        quarter, time_remaining = map(float, moment_key.split('_'))\n",
    "        if quarter not in moments_dict:\n",
    "            moments_dict[quarter] = []\n",
    "        moments_dict[quarter].append(time_remaining)\n",
    "\n",
    "    for frame_id in tqdm.tqdm(data):\n",
    "        quarter_time_key = str(data[frame_id]['quarter']) + '_' + str(data[frame_id]['time_remaining']) if data[frame_id]['time_remaining'] != None else None\n",
    "        if quarter_time_key:\n",
    "            total_frames += 1\n",
    "            quarter, time_remaining = map(float, quarter_time_key.split('_'))\n",
    "\n",
    "            match_found = False\n",
    "            if quarter in moments_dict:\n",
    "                closest_time = None\n",
    "                min_difference = float('inf')\n",
    "                for moment_time in moments_dict[quarter]:\n",
    "                    difference = abs(time_remaining - moment_time)\n",
    "                    if difference < min_difference:\n",
    "                        min_difference = difference\n",
    "                        closest_time = moment_time\n",
    "\n",
    "                if is_close(time_remaining, closest_time):\n",
    "                    frames_matched += 1\n",
    "                    match_found = True\n",
    "                    moment_key = f\"{int(quarter)}_{closest_time}\"\n",
    "                    frames_moments_map[frame_id] = moments_data[moment_key]\n",
    "            if not match_found:\n",
    "                frames_moments_map[frame_id] = None\n",
    "        else:\n",
    "            frames_moments_map[frame_id] = None\n",
    "\n",
    "    print(frames_matched, '/', total_frames)\n",
    "    return frames_moments_map\n",
    "\n",
    "# Example usage:\n",
    "with open(r'demo\\12.26.2015.PHI.at.PHX.timestamps.mod.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "frames_moments_map = map_frames_to_moments(data, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('demo/moments.json', 'w') as f:\n",
    "    json.dump(frames_moments_map, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "    # 1. Generate a viz for demo game\n",
    "    # 2. Write a summary report + upload changes\n",
    "    # 3. Apply for housing\n",
    "    # 4. Work on takehome exam\n",
    "    # 5. Read ViT review\n",
    "    # 6. Evening meditation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Frames: 100%|██████████| 4500/4500 [00:58<00:00, 76.41it/s] \n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load JSON data\n",
    "moments_path = 'demo/moments.json'  # Update this to the correct path to your moments.json file\n",
    "with open(moments_path, 'r') as file:\n",
    "    player_data = json.load(file)\n",
    "\n",
    "# Load the basketball court image\n",
    "court_path = 'court.png'  # Update this to the correct path to your court.png file\n",
    "court_img = plt.imread(court_path)\n",
    "\n",
    "# Dimensions of the court on the image\n",
    "court_width, court_height = 939, 500\n",
    "\n",
    "# Initialize video capture\n",
    "video_path = r'demo\\17769_12-27-2015_3175_Phoenix Suns_3224_Philadelphia 76ers_period2.mp4'  # Update this to the correct path to your video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Initialize video writer\n",
    "output_path = r'demo\\viz.mp4'  # Update this to your desired output path\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, frame_rate, (2*frame_width, frame_height))\n",
    "\n",
    "def format_time(seconds):\n",
    "    \"\"\"Convert time in seconds to minutes:seconds format.\"\"\"\n",
    "    minutes = int(seconds) // 60\n",
    "    seconds = seconds % 60\n",
    "    return f\"{minutes:02d}:{seconds:05.2f}\"\n",
    "\n",
    "# Function to draw player positions on the court\n",
    "def plot_positions_on_court(moment_data, ax):\n",
    "    if moment_data:\n",
    "        for player in moment_data['player_positions']:\n",
    "            x = (player['x_position'] / 100) * court_width\n",
    "            y = (player['y_position'] / 50) * court_height\n",
    "            color = 'red' if player['team_id'] == 1610612756 else 'blue' if player['team_id'] == 1610612755 else 'white'\n",
    "            ax.plot(x, y, 'o', color=color, markersize=15)\n",
    "\n",
    "        # Display the time remaining in the quarter\n",
    "        time_remaining = moment_data['time_remaining_in_quarter']\n",
    "        time_text = format_time(time_remaining)\n",
    "        ax.text(0.5, 0.02, f\"Time Remaining: {time_text}\", transform=ax.transAxes, \n",
    "                horizontalalignment='center', fontsize=12, bbox=dict(facecolor='black', alpha=0.5))\n",
    "\n",
    "start_time = 2 * 60 + 10  # 10 minutes and 10 seconds\n",
    "end_time = 2 * 60 + 30    # 10 minutes and 20 seconds\n",
    "start_frame = start_time * frame_rate\n",
    "end_frame = end_time * frame_rate\n",
    "\n",
    "for frame_index in tqdm(range(0, end_frame), desc=\"Processing Frames\"):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Skip frames outside the desired range\n",
    "    if frame_index < start_frame or frame_index > end_frame:\n",
    "        continue\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(court_width/100, court_height/100), dpi=100)\n",
    "    ax.imshow(court_img)\n",
    "    ax.axis('off')  # Turn off axis\n",
    "    \n",
    "    moment_data = player_data.get(str(frame_index))\n",
    "    plot_positions_on_court(moment_data, ax)\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    plot_image = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    plot_image = plot_image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    plot_image_resized = cv2.resize(plot_image, (frame_width, frame_height))\n",
    "\n",
    "    combined_frame = np.hstack((frame, plot_image_resized))\n",
    "    out.write(combined_frame)\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "cap.release()\n",
    "out.release()  # Release the video writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from viz import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35657/35657 [06:52<00:00, 86.47it/s] \n"
     ]
    }
   ],
   "source": [
    "visualize_timestamps(\n",
    "    r\"demo\\17769_12-27-2015_3175_Phoenix Suns_3224_Philadelphia 76ers_period2.mp4\", \n",
    "    r\"demo\\12.26.2015.PHI.at.PHX.timestamps.json\",\n",
    "    r\"viz.mp4\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "metadata": {
   "interpreter": {
    "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

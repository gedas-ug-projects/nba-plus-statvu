{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_blank_regex (testing.test_suite.RegexTests.test_blank_regex) ... ok\n",
      "test_regex_edge_cases (testing.test_suite.RegexTests.test_regex_edge_cases) ... ok\n",
      "test_regex_no_match (testing.test_suite.RegexTests.test_regex_no_match) ... ok\n",
      "test_regex_with_spaces (testing.test_suite.RegexTests.test_regex_with_spaces) ... ok\n",
      "test_time_coversion_blank (testing.test_suite.TimeConversionTests.test_time_coversion_blank) ... ok\n",
      "test_time_coversion_standard (testing.test_suite.TimeConversionTests.test_time_coversion_standard) ... ok\n",
      "test_time_rare_formatting (testing.test_suite.TimeConversionTests.test_time_rare_formatting) ... ok\n",
      "test_extract_text_with_paddle_blank (testing.test_suite.TextExtractionTests.test_extract_text_with_paddle_blank) ... ok\n",
      "test_extract_text_with_paddle_none (testing.test_suite.TextExtractionTests.test_extract_text_with_paddle_none) ... ok\n",
      "test_extract_text_with_paddle_valid (testing.test_suite.TextExtractionTests.test_extract_text_with_paddle_valid) ... ok\n",
      "test_extract_time_remaining_from_image_empty (testing.test_suite.TextExtractionTests.test_extract_time_remaining_from_image_empty) ... ok\n",
      "test_extract_time_remaining_from_image_none (testing.test_suite.TextExtractionTests.test_extract_time_remaining_from_image_none) ... ok\n",
      "test_extract_time_remaining_from_image_valid (testing.test_suite.TextExtractionTests.test_extract_time_remaining_from_image_valid) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 13 tests in 0.229s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "from testing.test_suite import run_all_tests\n",
    "\n",
    "run_all_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "def extract_clip(video_path, start_time, output_path):\n",
    "    \"\"\"\n",
    "    Extracts a 10-second clip from the specified video starting at `start_time`.\n",
    "    \n",
    "    :param video_path: Path to the source video file.\n",
    "    :param start_time: Start time for the clip in seconds.\n",
    "    :param output_path: Path where the extracted clip will be saved.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        video = VideoFileClip(video_path)\n",
    "        end_time = start_time + 10\n",
    "        clip = video.subclip(start_time, end_time)\n",
    "        clip.write_videofile(output_path, codec=\"libx264\")\n",
    "        print(f\"Clip successfully extracted to {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "in_path = r\"demo\\17590_01-23-2016_2_Golden State Warriors_9_Indiana Pacers_period4.mp4\"\n",
    "out_path = r\"demo/demo_17590_period_4.mp4\"\n",
    "extract_clip(in_path, 60, out_path)  # Extracts a clip starting at 1 minute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from temporal_grounding import extract_timestamps_from_video\n",
    "\n",
    "vp = r\"demo\\demo_17590_period_4.mp4\"\n",
    "op = \"demo/timestamps.json\"\n",
    "extract_timestamps_from_video(vp, op)\n",
    "\n",
    "# TODO\n",
    "# 1. Post Process Timestamps\n",
    "# 2. Map time-remaining to stavulog\n",
    "# 3. visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing/assets/blank_images/black.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from paddleocr import PaddleOCR\n",
    "\n",
    "MODEL_PATH = r\"models/yolo/weights/tr_roi_finetune_130_large.pt\"\n",
    "\n",
    "\n",
    "class Models:\n",
    "\n",
    "    yolo = yolo = YOLO(MODEL_PATH)\n",
    "    paddle_ocr = PaddleOCR(use_angle_cls=True,\n",
    "                           lang='en',\n",
    "                           show_log=False,\n",
    "                           det_db_score_mode='slow',\n",
    "                           ocr_version='PP-OCRv4',\n",
    "                           rec_algorithm='SVTR_LCNet',\n",
    "                           drop_score=0.8,\n",
    "                           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from typing import List\n",
    "\n",
    "from viz import visualize_timestamps\n",
    "from utilities.models import Models\n",
    "from utilities.constants import *\n",
    "\n",
    "def extract_text_with_paddle(image) -> List[str]:\n",
    "    \"\"\"\n",
    "    Returns a [str] containing all words found in a\n",
    "    provided PIL image.\n",
    "    \"\"\"\n",
    "\n",
    "    def resize_with_opencv(image_pil, new_size):\n",
    "        image_np = np.array(image_pil)\n",
    "        image_np = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)\n",
    "        resized_image = cv2.resize(image_np, new_size)\n",
    "        return resized_image\n",
    "\n",
    "    if image is None:\n",
    "        return []\n",
    "    image = Image.fromarray(image)\n",
    "    image = image.convert(\"RGB\")\n",
    "    ideal_height = 100\n",
    "    scale_factor = ideal_height / image.height\n",
    "    new_size = (int(image.width * scale_factor),\n",
    "                int(image.height * scale_factor))\n",
    "    image = resize_with_opencv(image, new_size)\n",
    "    results = []\n",
    "    raw_result = Models.paddle_ocr.ocr(image, det=False, rec=False, cls=False)\n",
    "    text_arr = raw_result[1]\n",
    "    for pred in text_arr:\n",
    "        word = pred[0]\n",
    "        results.append(word)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"read\")\n",
    "image = cv2.imread(r\"/Users/leviharris/Documents/contextualized-shot-quality-estimation/testing/assets/example_cropped_rois/time_remaining/time_remaining_1.png\")\n",
    "results = extract_text_with_paddle(image)\n",
    "assert results == [\"2:41\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from temporal_grounding import process_dir\n",
    "\n",
    "vid_dir = r\"demo/video_dir\"\n",
    "logs_dir = \"demo/timestamps_dir\"\n",
    "viz_dir = \"demo/viz_dir\"\n",
    "\n",
    "process_dir(vid_dir, logs_dir, viz_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from viz import visualize_timestamps\n",
    "\n",
    "visualize_timestamps(\n",
    "    video_path='demo/video_dir/707_01-17-2016_2976_Memphis Grizzlies_3173_New York Knicks_period1.mp4',\n",
    "    viz_path='demo/viz_dir/viz.mp4',\n",
    "    timestamps_path='demo/timestamps_dir/707_01-17-2016_2976_Memphis Grizzlies_3173_New York Knicks_period1.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from temporal_grounding import *\n",
    "from viz import *\n",
    "\n",
    "video_path = r'demo/video_dir/707_01-17-2016_2976_Memphis Grizzlies_3173_New York Knicks_period1.mp4'\n",
    "# demo_dir = r'demo'\n",
    "# start = time.time()\n",
    "# extract_timestamps_from_video(\n",
    "#     video_path, \n",
    "#     os.path.join(demo_dir, 'example.json')\n",
    "#     )\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from temporal_grounding import *\n",
    "from viz import *\n",
    "\n",
    "video_path = r'demo/video_dir/707_01-17-2016_2976_Memphis Grizzlies_3173_New York Knicks_period1.mp4'\n",
    "timestamps_path = r\"demo/example.json\"\n",
    "viz_path = r\"demo/viz_dir/viz.avi\"\n",
    "visualize_timestamps(video_path, timestamps_path, viz_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def interpolate_timestamps(timestamps_path: str, output_path) -> None:\n",
    "    \"\"\"\n",
    "    Interpolates time remaining values in a JSON file containing timestamp data.\n",
    "\n",
    "    Args:\n",
    "    file_path (str): The file path of the input JSON file with timestamp data.\n",
    "    output_path (str): The file path for the output JSON file with interpolated timestamps.\n",
    "\n",
    "    The function reads the timestamp data, interpolates the 'time_remaining' values, and writes\n",
    "    the updated data to a new JSON file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load data from the file\n",
    "    try:\n",
    "        with open(timestamps_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {timestamps_path}: {e}\")\n",
    "        return\n",
    "    \n",
    "    original_time_values = []\n",
    "\n",
    "    # Extract time_remaining values and handle None values\n",
    "    for key in data:\n",
    "        time_remaining = data[key].get('time_remaining', -1)\n",
    "        original_time_values.append(time_remaining if time_remaining is not None else -1)\n",
    "\n",
    "    last_seen_valid_time = -1\n",
    "    consecutive_frame_count = 0\n",
    "    interpolated_values = []\n",
    "\n",
    "    for value in original_time_values:\n",
    "        if value > 0:\n",
    "            if consecutive_frame_count == 0 or consecutive_frame_count > 30:\n",
    "                last_seen_valid_time = value\n",
    "                consecutive_frame_count = 0\n",
    "            else:\n",
    "                multiplier = math.floor((consecutive_frame_count / 30) * 25)\n",
    "                interpolated_value = round(value - (multiplier / 25), 2)\n",
    "                interpolated_values.append(interpolated_value)\n",
    "            consecutive_frame_count += 1\n",
    "        else:\n",
    "            interpolated_values.append(None)\n",
    "\n",
    "    # Update the data dictionary with interpolated values\n",
    "    for key, interpolated_value in zip(data, interpolated_values):\n",
    "        data[key]['time_remaining'] = interpolated_value\n",
    "\n",
    "    try:\n",
    "        with open(output_path, \"w\") as outfile:\n",
    "            json.dump(data, outfile, indent=4)\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing file {output_path}: {e}\")\n",
    "\n",
    "ts_path = r\"demo/example.json\"\n",
    "out_path = \"demo/example_post_processed.json\"\n",
    "interpolate_timestamps(ts_path, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

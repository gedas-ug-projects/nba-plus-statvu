{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "from ocr.paddle import extract_time_remaining_from_image_paddle\n",
    "from ocr.models import PaddleModel\n",
    "\n",
    "model = PaddleModel(device=0)\n",
    "\n",
    "img_dir = \"/playpen-storage/levlevi/nba-positions-videos-dataset/__old__/temp_162626_11-05-2015_3222_Denver Nuggets_3281_Utah Jazz_period1.mp4\"\n",
    "img_abs_paths = [os.path.join(img_dir, img) for img in os.listdir(img_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "paddle_dir = \"/playpen-storage/levlevi/nba-positions-videos-dataset/testing/quantitative-benchmark/pipeline/PaddleOCR\"\n",
    "os.chdir(paddle_dir)\n",
    "img_dir = \"/playpen-storage/levlevi/nba-positions-videos-dataset/testing/assets/example_cropped_rois/time_remaining\"\n",
    "\n",
    "predict_command = [\n",
    "    \"python3\", \"tools/infer/predict_rec.py\",\n",
    "    f\"--image_dir={img_dir}\",\n",
    "    \"--rec_model_dir=./en_PP-OCRv4_rec_infer/\",\n",
    "    \"--rec_char_dict_path=ppocr/utils/en_dict.txt\"\n",
    "]\n",
    "\n",
    "result = subprocess.run(predict_command, capture_output=True, text=True)\n",
    "\n",
    "# Step 4: Parse the console output\n",
    "output = result.stdout\n",
    "error = result.stderr\n",
    "\n",
    "# Print the output and error (if any)\n",
    "print(\"Output:\\n\", output)\n",
    "print(\"Error:\\n\", error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_arr = output.split(\":('\")\n",
    "preds = [x.split('\\n[')[0].replace(\")\", \"\").replace(\"'\", \"\").split(\", \") for x in output_arr][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import concurrent.futures\n",
    "import cv2\n",
    "import torch\n",
    "import os\n",
    "import concurrent\n",
    "import logging\n",
    "import subprocess\n",
    "import threading\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from transformers import logging\n",
    "\n",
    "from utils.constants import QUARTER_KEY, TIME_REMAINING_KEY, PAD, BREAK, CONF_THRESH\n",
    "from ocr.helpers import convert_time_to_float, find_time_remaining_from_results\n",
    "from ocr.models import YOLOModel\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "MAX_GPUS = 8\n",
    "ROI_STEP = 5\n",
    "TIME_REMAINING_STEP = 5\n",
    "\n",
    "ROI_MODELS = {}\n",
    "MODELS = {}\n",
    "\n",
    "def extract_timestamps_from_video(video_path: str, device: int = 0):\n",
    "    \"\"\"\n",
    "    Given a path to a basketball broadcast video,\n",
    "    returns a timestamps dict.\n",
    "    \"\"\"\n",
    "\n",
    "    assert os.path.exists(video_path)\n",
    "    tr_x1, tr_y1, tr_x2, tr_y2 = None, None, None, None\n",
    "\n",
    "    # create ROT det. model\n",
    "    if str(device) not in ROI_MODELS:\n",
    "        model = YOLOModel(device=device)\n",
    "        ROI_MODELS[str(device)] = model\n",
    "    yolo_model = ROI_MODELS[str(device)]\n",
    "\n",
    "    time_remaining_roi = extract_roi_from_video(video_path, yolo_model, device=device)\n",
    "    if time_remaining_roi is not None:\n",
    "        tr_x1, tr_y1, tr_x2, tr_y2 = time_remaining_roi\n",
    "    timestamps = {}\n",
    "    quarter = video_path[-5]  # period_x.mp4\n",
    "\n",
    "    temp_name = f\"temp_{os.path.basename(video_path)}\"\n",
    "    os.makedirs(temp_name, exist_ok=True)\n",
    "    temp_dir_path = os.path.join(os.getcwd(), temp_name)\n",
    "\n",
    "    def save_frame(image, path):\n",
    "        original_height, original_width = image.shape[:2]\n",
    "        new_height = 100\n",
    "        aspect_ratio = original_width / original_height\n",
    "        new_width = int(new_height * aspect_ratio)\n",
    "        resized_image = cv2.resize(image, (new_width, new_height))\n",
    "        cv2.imwrite(path, resized_image)\n",
    "\n",
    "    def save_all_images(vid_path: str, dst_dir: str):\n",
    "        if not os.path.exists(dst_dir):\n",
    "            os.makedirs(dst_dir)\n",
    "        \n",
    "        cap = cv2.VideoCapture(vid_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error opening video file: {vid_path}\")\n",
    "            return\n",
    "        \n",
    "        frame_number = 0\n",
    "        frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:\n",
    "            while frame_number < frame_cnt:\n",
    "                ret, frame = cap.read()\n",
    "                if (frame_number + 1) % TIME_REMAINING_STEP != 0:\n",
    "                    frame_number += 1\n",
    "                    continue\n",
    "                if not ret:\n",
    "                    break\n",
    "                frame = frame[tr_y1:tr_y2, tr_x1:tr_x2]\n",
    "                frame_filename = os.path.join(dst_dir, f\"{frame_number:05d}.png\")\n",
    "                executor.submit(save_frame, frame, frame_filename)\n",
    "                frame_number += 1\n",
    "        \n",
    "        cap.release()\n",
    "        # print(f\"Saved {frame_number} frames to {dst_dir}\")\n",
    "\n",
    "    # save all frames to a temp dir\n",
    "    save_all_images(video_path, temp_dir_path)\n",
    "\n",
    "    paddle_dir = \"/playpen-storage/levlevi/nba-positions-videos-dataset/testing/quantitative-benchmark/pipeline/PaddleOCR\"\n",
    "    os.chdir(paddle_dir)\n",
    "\n",
    "    # batch infer w/ paddel\n",
    "    predict_command = [\n",
    "        \"python3\", \"tools/infer/predict_rec.py\",\n",
    "        f\"--image_dir={temp_dir_path}\",\n",
    "        \"--rec_model_dir=./en_PP-OCRv4_rec_infer/\",\n",
    "        \"--rec_char_dict_path=ppocr/utils/en_dict.txt\",\n",
    "        \"--use_gpu=True\",\n",
    "    ]\n",
    "\n",
    "    result = subprocess.run(predict_command, capture_output=True, text=True)\n",
    "    shutil.rmtree(temp_dir_path)\n",
    "\n",
    "    output = result.stdout\n",
    "    output_arr = output.split(\":('\")\n",
    "    preds = [x.split('\\n[')[0].replace(\")\", \"\").replace(\"'\", \"\").split(\", \") for x in output_arr][1:]\n",
    "    return result\n",
    "\n",
    "    for frame_idx, pred in enumerate(preds):\n",
    "        time_remaining, conf = pred[0], pred[1]\n",
    "        time_remaining = find_time_remaining_from_results([time_remaining])\n",
    "        time_remaining = convert_time_to_float(time_remaining)\n",
    "        timestamps[str(frame_idx)] = {\n",
    "            \"quarter\": quarter,\n",
    "            \"time_remaining\": time_remaining,\n",
    "            \"conf\": conf\n",
    "        }\n",
    "        if frame_idx == BREAK:\n",
    "            break\n",
    "\n",
    "    return video_path, timestamps\n",
    "\n",
    "\n",
    "def extract_roi_from_video(video_path: str, model: YOLOModel, device:int=0):\n",
    "    \"\"\"\n",
    "    Find time-remaining roi from video. Assumes static, naive approach.\n",
    "    Returns a tensor with format: [x1, y1, x2, y2] or None if no\n",
    "    ROI is found.\n",
    "    \"\"\"\n",
    "\n",
    "    assert os.path.isfile(video_path), f\"Error: bad path to video {video_path}.\"\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    time_remaining_roi = None\n",
    "\n",
    "    highest_conf = 0.0\n",
    "    best_roi = None\n",
    "    step = ROI_STEP\n",
    "\n",
    "    # TODO: batch process ROIs\n",
    "    start = time.time()\n",
    "    for i in range(frames_cnt):\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        if i % step == 0:\n",
    "            results = model.model(frame, verbose=False)\n",
    "            classes, conf, boxes = (\n",
    "                results[0].boxes.cls,\n",
    "                results[0].boxes.conf,\n",
    "                results[0].boxes.xyxy,\n",
    "            )\n",
    "            classes_conf = torch.stack((classes, conf), dim=1)\n",
    "            predictions = torch.cat((classes_conf, boxes), dim=1)\n",
    "            conf_mask = predictions[:, 1] > CONF_THRESH\n",
    "            pred_thresh = predictions[conf_mask]\n",
    "            for row in pred_thresh:\n",
    "                if row[0] == QUARTER_KEY:\n",
    "                    pass\n",
    "                elif row[0] == TIME_REMAINING_KEY:\n",
    "                    time_remaining_roi = row[2:].to(torch.int)\n",
    "            for row in predictions:\n",
    "                if row[0] == QUARTER_KEY:\n",
    "                    pass\n",
    "                elif row[0] == TIME_REMAINING_KEY:\n",
    "                    if row[1] > highest_conf:\n",
    "                        highest_conf = row[1]\n",
    "                        best_roi = row[2:].to(torch.int)\n",
    "            if time_remaining_roi is not None:\n",
    "                break\n",
    "    end = time.time()\n",
    "    # print(f\"ROI extraction time: {end - start}\")\n",
    "    return best_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_vid = \"/playpen-storage/levlevi/nba-positions-videos-dataset/testing/quantitative-benchmark/assets/test-set/clip_17635_01-16-2016_3280_Milwaukee Bucks_79_Atlanta Hawks_period1.mp4\"\n",
    "results = extract_timestamps_from_video(ex_vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = results.stdout\n",
    "output_arr = output.split(\":('\")\n",
    "preds = [x.split('\\n[')[0].replace(\")\", \"\").replace(\"'\", \"\").split(\", \") for x in output_arr][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1:21', '0.9716400504112244'], ['1:21', '0.9716400504112244'], ['1:21', '0.9716400504112244'], ['1:21', '0.9716400504112244'], ['1:21', '0.9716400504112244'], ['1:21', '0.9714486598968506'], ['1:21', '0.9714486598968506'], ['1:21', '0.9714486598968506'], ['1:21', '0.9714486598968506'], ['1:21', '0.9714486598968506'], ['1:21', '0.9730978608131409'], ['1:21', '0.9730978608131409'], ['1:21', '0.9730978608131409'], ['1:21', '0.9730978608131409'], ['1:21', '0.9730978608131409'], ['1:21', '0.9719265699386597'], ['1:21', '0.9719265699386597'], ['1:21', '0.9719265699386597'], ['1:21', '0.9719265699386597'], ['1:21', '0.9719265699386597'], ['1:21', '0.9720696210861206'], ['1:21', '0.9720696210861206'], ['1:21', '0.9720696210861206'], ['1:21', '0.9720696210861206'], ['1:21', '0.9720696210861206'], ['1:21', '0.9718112945556641'], ['1:21', '0.9718112945556641'], ['1:21', '0.9718112945556641'], ['1:21', '0.9718112945556641'], ['1:21', '0.9718112945556641'], ['1:21', '0.9721224904060364'], ['1:21', '0.9721224904060364'], ['1:21', '0.9721224904060364'], ['1:21', '0.9721224904060364'], ['1:21', '0.9721224904060364'], ['1:21', '0.9719921350479126'], ['1:21', '0.9719921350479126'], ['1:21', '0.9719921350479126'], ['1:21', '0.9719921350479126'], ['1:21', '0.9719921350479126'], ['1:21', '0.9719921350479126'], ['1:21', '0.9719921350479126'], ['1:21', '0.9719921350479126'], ['1:21', '0.9719921350479126'], ['1:21', '0.9719921350479126'], ['1:21', '0.9719921350479126'], ['1:21', '0.9719921350479126'], ['1:21', '0.9719921350479126'], ['1:21', '0.9719921350479126'], ['1:21', '0.9719921350479126'], ['1:21', '0.9721246957778931'], ['1:21', '0.9721246957778931'], ['1:21', '0.9721246957778931'], ['1:21', '0.9721246957778931'], ['1:21', '0.9721246957778931'], ['1:21', '0.9721246957778931'], ['1:21', '0.9721246957778931'], ['1:21', '0.9721246957778931'], ['1:21', '0.9721246957778931'], ['1:21', '0.9721246957778931'], ['1:21', '0.9743187427520752'], ['1:21', '0.9743187427520752'], ['1:21', '0.9743187427520752'], ['1:21', '0.9743187427520752'], ['1:21', '0.9743187427520752'], ['1:21', '0.9743187427520752'], ['1:21', '0.9743187427520752'], ['1:21', '0.9743187427520752'], ['1:21', '0.9743187427520752'], ['1:21', '0.9743187427520752'], ['1:21', '0.9742546677589417'], ['1:21', '0.9742546677589417'], ['1:21', '0.9742546677589417'], ['1:21', '0.9742546677589417'], ['1:21', '0.9742546677589417'], ['1:21', '0.9742546677589417'], ['1:21', '0.9742546677589417'], ['1:21', '0.9742546677589417'], ['1:21', '0.9742546677589417'], ['1:21', '0.9742546677589417'], ['1:21', '0.9752540588378906'], ['1:21', '0.9752540588378906'], ['1:21', '0.9752540588378906'], ['1:21', '0.9752540588378906'], ['1:21', '0.9752540588378906'], ['1:20', '0.9741477966308594'], ['1:20', '0.9741477966308594'], ['1:20', '0.9741477966308594'], ['1:20', '0.9741477966308594'], ['1:20', '0.9741477966308594'], ['1:20', '0.9657558798789978'], ['1:20', '0.9657558798789978'], ['1:20', '0.9657558798789978'], ['1:20', '0.9657558798789978'], ['1:20', '0.9657558798789978'], ['1:20', '0.9657558798789978'], ['1:20', '0.9657558798789978'], ['1:20', '0.9657558798789978'], ['1:20', '0.9657558798789978'], ['1:20', '0.9657558798789978'], ['1:20', '0.9661966562271118'], ['1:20', '0.9661966562271118'], ['1:20', '0.9661966562271118'], ['1:20', '0.9661966562271118'], ['1:20', '0.9661966562271118'], ['1:20', '0.9664661288261414'], ['1:20', '0.9664661288261414'], ['1:20', '0.9664661288261414'], ['1:20', '0.9664661288261414'], ['1:20', '0.9664661288261414'], ['1:20', '0.9654322266578674'], ['1:20', '0.9654322266578674'], ['1:20', '0.9654322266578674'], ['1:20', '0.9654322266578674'], ['1:20', '0.9654322266578674'], ['1:19', '0.9782266020774841'], ['1:19', '0.9782266020774841'], ['1:19', '0.9782266020774841'], ['1:19', '0.9782266020774841'], ['1:19', '0.9782266020774841'], ['1:19', '0.9860105514526367'], ['1:19', '0.9860105514526367'], ['1:19', '0.9860105514526367'], ['1:19', '0.9860105514526367'], ['1:19', '0.9860105514526367'], ['1:19', '0.9870262742042542'], ['1:19', '0.9870262742042542'], ['1:19', '0.9870262742042542'], ['1:19', '0.9870262742042542'], ['1:19', '0.9870262742042542'], ['1:19', '0.987125813961029'], ['1:19', '0.987125813961029'], ['1:19', '0.987125813961029'], ['1:19', '0.987125813961029'], ['1:19', '0.987125813961029'], ['1:19', '0.9868322610855103'], ['1:19', '0.9868322610855103'], ['1:19', '0.9868322610855103'], ['1:19', '0.9868322610855103'], ['1:19', '0.9868322610855103'], ['1:19', '0.9868322610855103'], ['1:19', '0.9868322610855103'], ['1:19', '0.9868322610855103'], ['1:19', '0.9868322610855103'], ['1:19', '0.9868322610855103'], ['1:18', '0.9370173811912537'], ['1:18', '0.9370173811912537'], ['1:18', '0.9370173811912537'], ['1:18', '0.9370173811912537'], ['1:18', '0.9370173811912537'], ['1:18', '0.9768967628479004'], ['1:18', '0.9768967628479004'], ['1:18', '0.9768967628479004'], ['1:18', '0.9768967628479004'], ['1:18', '0.9768967628479004'], ['1:18', '0.9768967628479004'], ['1:18', '0.9768967628479004'], ['1:18', '0.9768967628479004'], ['1:18', '0.9768967628479004'], ['1:18', '0.9768967628479004'], ['1:18', '0.9768967628479004'], ['1:18', '0.9768967628479004'], ['1:18', '0.9768967628479004'], ['1:18', '0.9768967628479004'], ['1:18', '0.9768967628479004'], ['1:18', '0.9768967628479004'], ['1:18', '0.9768967628479004'], ['1:18', '0.9768967628479004'], ['1:18', '0.9768967628479004'], ['1:18', '0.9768967628479004'], ['1:18', '0.9790789484977722'], ['1:18', '0.9790789484977722'], ['1:18', '0.9790789484977722'], ['1:18', '0.9790789484977722'], ['1:18', '0.9790789484977722'], ['1:17', '0.9879894256591797'], ['1:17', '0.9879894256591797'], ['1:17', '0.9879894256591797'], ['1:17', '0.9879894256591797'], ['1:17', '0.9879894256591797'], ['1:17', '0.9889943599700928'], ['1:17', '0.9889943599700928'], ['1:17', '0.9889943599700928'], ['1:17', '0.9889943599700928'], ['1:17', '0.9889943599700928'], ['1:17', '0.9889943599700928'], ['1:17', '0.9889943599700928'], ['1:17', '0.9889943599700928'], ['1:17', '0.9889943599700928'], ['1:17', '0.9889943599700928'], ['1:17', '0.9914654493331909'], ['1:17', '0.9914654493331909'], ['1:17', '0.9914654493331909'], ['1:17', '0.9914654493331909'], ['1:17', '0.9914654493331909'], ['1:17', '0.9916021227836609'], ['1:17', '0.9916021227836609'], ['1:17', '0.9916021227836609'], ['1:17', '0.9916021227836609'], ['1:17', '0.9916021227836609'], ['1:17', '0.9882242679595947'], ['1:17', '0.9882242679595947'], ['1:17', '0.9882242679595947'], ['1:17', '0.9882242679595947'], ['1:17', '0.9882242679595947'], ['1:16', '0.9859244227409363'], ['1:16', '0.9859244227409363'], ['1:16', '0.9859244227409363'], ['1:16', '0.9859244227409363'], ['1:16', '0.9859244227409363'], ['1:16', '0.9788057208061218'], ['1:16', '0.9788057208061218'], ['1:16', '0.9788057208061218'], ['1:16', '0.9788057208061218'], ['1:16', '0.9788057208061218'], ['1:16', '0.9781898856163025'], ['1:16', '0.9781898856163025'], ['1:16', '0.9781898856163025'], ['1:16', '0.9781898856163025'], ['1:16', '0.9781898856163025'], ['1:16', '0.9782404899597168'], ['1:16', '0.9782404899597168'], ['1:16', '0.9782404899597168'], ['1:16', '0.9782404899597168'], ['1:16', '0.9782404899597168'], ['1:16', '0.9780277013778687'], ['1:16', '0.9780277013778687'], ['1:16', '0.9780277013778687'], ['1:16', '0.9780277013778687'], ['1:16', '0.9780277013778687'], ['1:16', '0.9801168441772461'], ['1:16', '0.9801168441772461'], ['1:16', '0.9801168441772461'], ['1:16', '0.9801168441772461'], ['1:16', '0.9801168441772461'], ['1:15', '0.9806780219078064'], ['1:15', '0.9806780219078064'], ['1:15', '0.9806780219078064'], ['1:15', '0.9806780219078064'], ['1:15', '0.9806780219078064'], ['1:15', '0.9769314527511597'], ['1:15', '0.9769314527511597'], ['1:15', '0.9769314527511597'], ['1:15', '0.9769314527511597'], ['1:15', '0.9769314527511597'], ['1:15', '0.976883053779602'], ['1:15', '0.976883053779602'], ['1:15', '0.976883053779602'], ['1:15', '0.976883053779602'], ['1:15', '0.976883053779602'], ['1:15', '0.9792822599411011'], ['1:15', '0.9792822599411011'], ['1:15', '0.9792822599411011'], ['1:15', '0.9792822599411011'], ['1:15', '0.9792822599411011'], ['1:15', '0.9776366949081421'], ['1:15', '0.9776366949081421'], ['1:15', '0.9776366949081421'], ['1:15', '0.9776366949081421'], ['1:15', '0.9776366949081421'], ['1:15', '0.9783229827880859'], ['1:15', '0.9783229827880859'], ['1:15', '0.9783229827880859'], ['1:15', '0.9783229827880859'], ['1:15', '0.9783229827880859'], ['1:14', '0.9479366540908813'], ['1:14', '0.9479366540908813'], ['1:14', '0.9479366540908813'], ['1:14', '0.9479366540908813'], ['1:14', '0.9479366540908813'], ['1:14', '0.9834833741188049\\n'], ['1:14', '0.9834833741188049\\n'], ['1:14', '0.9834833741188049\\n'], ['1:14', '0.9834833741188049\\n'], ['1:14', '0.9834833741188049\\n']]\n"
     ]
    }
   ],
   "source": [
    "preds_extended = []\n",
    "last_frame = None\n",
    "original_size = len(preds)\n",
    "extended_size = TIME_REMAINING_STEP * original_size\n",
    "\n",
    "i = 0  # index for preds\n",
    "j = 0  # index for preds_extended\n",
    "\n",
    "while j < extended_size:\n",
    "    if (j) % TIME_REMAINING_STEP == 0 and i < original_size:\n",
    "        # Read frame based on TIME_REMAINING_STEP condition\n",
    "        last_frame = preds[i]\n",
    "        preds_extended.append(last_frame)\n",
    "        i += 1\n",
    "    else:\n",
    "        # Use the last read frame to fill unread frames\n",
    "        if last_frame is not None:\n",
    "            preds_extended.append(last_frame)\n",
    "        else:\n",
    "            # If no last_frame is available (initial case), append a placeholder or empty value\n",
    "            preds_extended.append(None)  # Assuming None as a placeholder for unread frames\n",
    "    j += 1\n",
    "\n",
    "# At this point, preds_extended has the desired size and is filled correctly\n",
    "print(preds_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shot-loc-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "from ocr.paddle import extract_time_remaining_from_image_paddle\n",
    "from ocr.models import PaddleModel\n",
    "\n",
    "model = PaddleModel(device=0)\n",
    "\n",
    "img_dir = \"/playpen-storage/levlevi/nba-positions-videos-dataset/__old__/temp_162626_11-05-2015_3222_Denver Nuggets_3281_Utah Jazz_period1.mp4\"\n",
    "img_abs_paths = [os.path.join(img_dir, img) for img in os.listdir(img_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "paddle_dir = \"/playpen-storage/levlevi/nba-positions-videos-dataset/testing/quantitative-benchmark/pipeline/PaddleOCR\"\n",
    "os.chdir(paddle_dir)\n",
    "img_dir = \"/playpen-storage/levlevi/nba-positions-videos-dataset/testing/assets/example_cropped_rois/time_remaining\"\n",
    "\n",
    "predict_command = [\n",
    "    \"python3\", \"tools/infer/predict_rec.py\",\n",
    "    f\"--image_dir={img_dir}\",\n",
    "    \"--rec_model_dir=./en_PP-OCRv4_rec_infer/\",\n",
    "    \"--rec_char_dict_path=ppocr/utils/en_dict.txt\"\n",
    "]\n",
    "\n",
    "result = subprocess.run(predict_command, capture_output=True, text=True)\n",
    "\n",
    "# Step 4: Parse the console output\n",
    "output = result.stdout\n",
    "error = result.stderr\n",
    "\n",
    "# Print the output and error (if any)\n",
    "print(\"Output:\\n\", output)\n",
    "print(\"Error:\\n\", error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_arr = output.split(\":('\")\n",
    "preds = [x.split('\\n[')[0].replace(\")\", \"\").replace(\"'\", \"\").split(\", \") for x in output_arr][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import concurrent.futures\n",
    "import cv2\n",
    "import torch\n",
    "import os\n",
    "import concurrent\n",
    "import logging\n",
    "import subprocess\n",
    "import threading\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "from utils.constants import QUARTER_KEY, TIME_REMAINING_KEY, PAD, BREAK, CONF_THRESH\n",
    "from ocr.helpers import convert_time_to_float, find_time_remaining_from_results\n",
    "from ocr.models import YOLOModel\n",
    "\n",
    "# logging.set_verbosity_error()\n",
    "\n",
    "MAX_GPUS = 8\n",
    "ROI_STEP = 5\n",
    "TIME_REMAINING_STEP = 5\n",
    "\n",
    "ROI_MODELS = {}\n",
    "MODELS = {}\n",
    "\n",
    "def extract_timestamps_from_video(video_path: str, device: int = 0):\n",
    "    \"\"\"\n",
    "    Given a path to a basketball broadcast video,\n",
    "    returns a timestamps dict.\n",
    "    \"\"\"\n",
    "\n",
    "    assert os.path.exists(video_path)\n",
    "    tr_x1, tr_y1, tr_x2, tr_y2 = None, None, None, None\n",
    "\n",
    "    # create ROT det. model\n",
    "    if str(device) not in ROI_MODELS:\n",
    "        model = YOLOModel(device=device)\n",
    "        ROI_MODELS[str(device)] = model\n",
    "    yolo_model = ROI_MODELS[str(device)]\n",
    "\n",
    "    time_remaining_roi = extract_roi_from_video(video_path, yolo_model, device=device)\n",
    "    if time_remaining_roi is not None:\n",
    "        tr_x1, tr_y1, tr_x2, tr_y2 = time_remaining_roi\n",
    "    timestamps = {}\n",
    "    quarter = video_path[-5]  # period_x.mp4\n",
    "\n",
    "    temp_name = f\"temp_{os.path.basename(video_path)}\"\n",
    "    os.mkdir(temp_name)\n",
    "    temp_dir_path = os.path.join(os.getcwd(), temp_name)\n",
    "\n",
    "    def save_frame(image, path):\n",
    "        original_height, original_width = image.shape[:2]\n",
    "        new_height = 50\n",
    "        aspect_ratio = original_width / original_height\n",
    "        new_width = int(new_height * aspect_ratio)\n",
    "        resized_image = cv2.resize(image, (new_width, new_height))\n",
    "        cv2.imwrite(path, resized_image)\n",
    "\n",
    "    def save_all_images(vid_path: str, dst_dir: str):\n",
    "        if not os.path.exists(dst_dir):\n",
    "            os.makedirs(dst_dir)\n",
    "    \n",
    "        cap = cv2.VideoCapture(vid_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error opening video file: {vid_path}\")\n",
    "            return\n",
    "        \n",
    "        frame_number = 0\n",
    "        frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        max_workers = min(16, os.cpu_count())\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            futures = []\n",
    "            while frame_number < frame_cnt:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                if frame_number % TIME_REMAINING_STEP == 0:\n",
    "                    frame = frame[tr_y1:tr_y2, tr_x1:tr_x2]\n",
    "                    frame_filename = os.path.join(dst_dir, f\"{frame_number:05d}.png\")\n",
    "                    futures.append(executor.submit(save_frame, frame, frame_filename))\n",
    "                frame_number += 1\n",
    "            concurrent.futures.wait(futures)\n",
    "        \n",
    "        cap.release()\n",
    "\n",
    "    # save all frames to a temp dir\n",
    "    save_all_images(video_path, temp_dir_path)\n",
    "\n",
    "    paddle_dir = \"/playpen-storage/levlevi/nba-positions-videos-dataset/testing/quantitative-benchmark/pipeline/PaddleOCR\"\n",
    "    os.chdir(paddle_dir)\n",
    "\n",
    "    # batch infer w/ paddel\n",
    "    predict_command = [\n",
    "        \"python3\", \"tools/infer/predict_rec.py\",\n",
    "        f\"--image_dir={temp_dir_path}\",\n",
    "        \"--rec_model_dir=./en_PP-OCRv4_rec_infer/\",\n",
    "        \"--rec_char_dict_path=ppocr/utils/en_dict.txt\",\n",
    "        \"--use_gpu=True\",\n",
    "        # \"--use_tensorrt=True\",\n",
    "    ]\n",
    "\n",
    "    result = subprocess.run(predict_command, capture_output=True, text=True)\n",
    "    return result\n",
    "    shutil.rmtree(temp_dir_path)\n",
    "\n",
    "    output = result.stdout\n",
    "    output_arr = output.split(\":('\")\n",
    "    preds = [x.split('\\n[')[0].replace(\")\", \"\").replace(\"'\", \"\").split(\", \") for x in output_arr][1:]\n",
    "\n",
    "    def interpolate_missing_frames(preds):\n",
    "\n",
    "        preds_extended = []\n",
    "        preds = preds.copy()\n",
    "        last_frame = None\n",
    "        original_size = len(preds)\n",
    "        extended_size = TIME_REMAINING_STEP * original_size\n",
    "\n",
    "        i = 0  # index for preds\n",
    "        j = 0  # index for preds_extended\n",
    "\n",
    "        while j < extended_size:\n",
    "            if (j) % TIME_REMAINING_STEP == 0 and i < original_size:\n",
    "                # Read frame based on TIME_REMAINING_STEP condition\n",
    "                last_frame = preds[i]\n",
    "                preds_extended.append(last_frame)\n",
    "                i += 1\n",
    "            else:\n",
    "                # Use the last read frame to fill unread frames\n",
    "                if last_frame is not None:\n",
    "                    preds_extended.append(last_frame)\n",
    "                else:\n",
    "                    # If no last_frame is available (initial case), append a placeholder or empty value\n",
    "                    preds_extended.append(None)  # Assuming None as a placeholder for unread frames\n",
    "            j += 1\n",
    "\n",
    "        return preds_extended\n",
    "    \n",
    "    preds = interpolate_missing_frames(preds)\n",
    "\n",
    "    for frame_idx, pred in enumerate(preds):\n",
    "        time_remaining, conf = pred[0], pred[1]\n",
    "        time_remaining = find_time_remaining_from_results([time_remaining])\n",
    "        time_remaining = convert_time_to_float(time_remaining)\n",
    "        timestamps[str(frame_idx)] = {\n",
    "            \"quarter\": quarter,\n",
    "            \"time_remaining\": time_remaining,\n",
    "            \"conf\": conf\n",
    "        }\n",
    "        if frame_idx == BREAK:\n",
    "            break\n",
    "\n",
    "    return video_path, timestamps\n",
    "\n",
    "\n",
    "def extract_roi_from_video(video_path: str, model: YOLOModel, device:int=0):\n",
    "    \"\"\"\n",
    "    Find time-remaining roi from video. Assumes static, naive approach.\n",
    "    Returns a tensor with format: [x1, y1, x2, y2] or None if no\n",
    "    ROI is found.\n",
    "    \"\"\"\n",
    "\n",
    "    assert os.path.isfile(video_path), f\"Error: bad path to video {video_path}.\"\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    time_remaining_roi = None\n",
    "\n",
    "    highest_conf = 0.0\n",
    "    best_roi = None\n",
    "    step = ROI_STEP\n",
    "\n",
    "    # TODO: batch process ROIs\n",
    "    start = time.time()\n",
    "    for i in range(frames_cnt):\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        if i % step == 0:\n",
    "            results = model.model(frame, verbose=False)\n",
    "            classes, conf, boxes = (\n",
    "                results[0].boxes.cls,\n",
    "                results[0].boxes.conf,\n",
    "                results[0].boxes.xyxy,\n",
    "            )\n",
    "            classes_conf = torch.stack((classes, conf), dim=1)\n",
    "            predictions = torch.cat((classes_conf, boxes), dim=1)\n",
    "            conf_mask = predictions[:, 1] > CONF_THRESH\n",
    "            pred_thresh = predictions[conf_mask]\n",
    "            for row in pred_thresh:\n",
    "                if row[0] == QUARTER_KEY:\n",
    "                    pass\n",
    "                elif row[0] == TIME_REMAINING_KEY:\n",
    "                    time_remaining_roi = row[2:].to(torch.int)\n",
    "            for row in predictions:\n",
    "                if row[0] == QUARTER_KEY:\n",
    "                    pass\n",
    "                elif row[0] == TIME_REMAINING_KEY:\n",
    "                    if row[1] > highest_conf:\n",
    "                        highest_conf = row[1]\n",
    "                        best_roi = row[2:].to(torch.int)\n",
    "            if time_remaining_roi is not None:\n",
    "                break\n",
    "    end = time.time()\n",
    "    # print(f\"ROI extraction time: {end - start}\")\n",
    "    return best_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_vid = \"/playpen-storage/levlevi/nba-positions-videos-dataset/testing/quantitative-benchmark/assets/test-set/clip_17635_01-16-2016_3280_Milwaukee Bucks_79_Atlanta Hawks_period1.mp4\"\n",
    "results = extract_timestamps_from_video(ex_vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = results.stdout\n",
    "# output_arr = output.split(\":('\")\n",
    "# preds = [x.split('\\n[')[0].replace(\")\", \"\").replace(\"'\", \"\").split(\", \") for x in output_arr][1:]\n",
    "\n",
    "results.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_extended = []\n",
    "last_frame = None\n",
    "original_size = len(preds)\n",
    "extended_size = TIME_REMAINING_STEP * original_size\n",
    "\n",
    "i = 0  # index for preds\n",
    "j = 0  # index for preds_extended\n",
    "\n",
    "while j < extended_size:\n",
    "    if (j) % TIME_REMAINING_STEP == 0 and i < original_size:\n",
    "        # Read frame based on TIME_REMAINING_STEP condition\n",
    "        last_frame = preds[i]\n",
    "        preds_extended.append(last_frame)\n",
    "        i += 1\n",
    "    else:\n",
    "        # Use the last read frame to fill unread frames\n",
    "        if last_frame is not None:\n",
    "            preds_extended.append(last_frame)\n",
    "        else:\n",
    "            # If no last_frame is available (initial case), append a placeholder or empty value\n",
    "            preds_extended.append(None)  # Assuming None as a placeholder for unread frames\n",
    "    j += 1\n",
    "\n",
    "# At this point, preds_extended has the desired size and is filled correctly\n",
    "print(preds_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running verify PaddlePaddle program ... \n",
      "PaddlePaddle works well on 1 CPU.\n",
      "PaddlePaddle is installed successfully! Let's start deep learning with PaddlePaddle now.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0528 08:16:20.736145 3762739 program_interpreter.cc:212] New Executor is Running.\n",
      "I0528 08:16:20.816885 3762739 interpreter_util.cc:624] Standalone Executor is Used.\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "paddle.utils.run_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shot-loc-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

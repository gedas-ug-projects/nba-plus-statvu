TODO

We may need more models:

New Pipeline Proposal:
    1. frame -> model_1: object-detection -> ROI's
    2. ROI's -> model_2: fine-tuned OCR -> predictions
    3. predictions -> in-domain knowlege + postprocessing (i.e. interpolation) -> done

- Problem:
    - Tesseract OCR doing a very poor job of reading text from an entire ROI
- Solutions
    - 1. Need domain-specific text-extraction (TesseractOCR good for now but we need fine-tuned models)
    - 2. Maybe easy OCR just better lol
    - 3. Better pre-processing
    - 4. Better KC


1. Frame -> Clock-GFX OD
- Specs:
    - Model: YOLO-8 Nano
    - Object Classes: [clock]
    - Annotations: 50 videos (unique gfx) w/ ~1100 frames from each. ~20k total
    - Preprocessing
        - Resize all to 720x1280
        - Desaturate a little
    - Augmented Annotations:
        - Random flips (included flipped version of frames across vertical axis) +20k
        - Some random image pre-processing (saturation, contrast, brightness, etc) + 40k
        - Final dataset size ~80k images

    - Training params: 300 epochs, batch-size: 16, img-size: 1280
    - Q: What is a clock-gfx
        A: The entire graphic containing the time_remaining/quarter values from an 
2. Clock-GFX -> Semantic ROI's
- Object: break entire clock ROI into semantic labels
- Specs
    - Model YOLO-8 Nano

Or... we can do this the fun way

1. Frame -> Semantic-ROI's
- Specs:
    - Model: YOLO-8 Nano
    - Object Classes: [time_remaining, quarter]
    - Benefits: if we can train a reliable OD -- can handle edge cases where roi's non-static
    - Annotations: ~100 unqiue gfx, ~50k annotations/class -> 100k total or ~1k/video
    - Preprocessing:
        - Train on color or grayscaled? Color b/c pretraining on COCO which is color.
        - None for now.
    - DB Size: ~50k images so ~5GB is target (i.e. 1/5 of COCO).

